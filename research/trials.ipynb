{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9df7c70a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing\n"
     ]
    }
   ],
   "source": [
    "print(\"testing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fa464d6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/georgelin/Desktop/Projects/medical_chat_LLM/research'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "490c9cba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current directory: /Users/georgelin/Desktop/Projects/medical_chat_LLM/research\n",
      "Project root: /Users/georgelin/Desktop/Projects/medical_chat_LLM\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# Simple fix: find project root from current location\n",
    "current_dir = Path.cwd()\n",
    "print(f\"Current directory: {current_dir}\")\n",
    "\n",
    "# If we're in research folder, go up one level to project root\n",
    "if current_dir.name == 'research':\n",
    "    project_root = current_dir.parent\n",
    "else:\n",
    "    # If not in research, try to find it by looking for data folder\n",
    "    project_root = current_dir\n",
    "    # Walk up until we find the data folder\n",
    "    for parent in [current_dir] + list(current_dir.parents):\n",
    "        if (parent / 'data').exists() and (parent / 'app.py').exists():\n",
    "            project_root = parent\n",
    "            break\n",
    "\n",
    "print(f\"Project root: {project_root}\")\n",
    "os.chdir(str(project_root))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "119a2075",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/georgelin/Desktop/Projects/medical_chat_LLM'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8eedcfe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import PyPDFLoader, DirectoryLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "18b34085",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract text from PDF files\n",
    "def load_pdf_files(data):\n",
    "    loader = DirectoryLoader(\n",
    "        data,\n",
    "        glob=\"*.pdf\",\n",
    "        loader_cls=PyPDFLoader\n",
    "    )\n",
    "\n",
    "    documents = loader.load()\n",
    "    return documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bf6002f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Found data directory: /Users/georgelin/Desktop/Projects/medical_chat_LLM/data\n",
      "PDF files in data: ['5812IFU.pdf']\n",
      "✅ Successfully loaded 500 documents\n"
     ]
    }
   ],
   "source": [
    "# Verify data folder exists and load PDFs\n",
    "data_path = \"data\"\n",
    "if os.path.exists(data_path):\n",
    "    print(f\"✅ Found data directory: {os.path.abspath(data_path)}\")\n",
    "    pdf_files = [f for f in os.listdir(data_path) if f.endswith('.pdf')]\n",
    "    print(f\"PDF files in data: {pdf_files}\")\n",
    "    extracted_data = load_pdf_files(data_path)\n",
    "    print(f\"✅ Successfully loaded {len(extracted_data)} documents\")\n",
    "else:\n",
    "    print(f\"❌ Data directory not found at: {os.path.abspath(data_path)}\")\n",
    "    print(f\"Current directory: {os.getcwd()}\")\n",
    "    print(f\"Available items: {os.listdir('.')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b2b5e34a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "from langchain.schema import Document\n",
    "\n",
    "def filter_to_minimal_docs(docs: List[Document]) -> List[Document]:\n",
    "    \"\"\"\n",
    "    Given a list of Document objects, return a new list of Document objects\n",
    "    containing only 'source' in metadata and the original page_content.\n",
    "    \"\"\"\n",
    "    minimal_docs: List[Document] = []\n",
    "    for doc in docs:\n",
    "        src = doc.metadata.get(\"source\")\n",
    "        minimal_docs.append(\n",
    "            Document(\n",
    "                page_content=doc.page_content,\n",
    "                metadata={\"source\": src}\n",
    "            )\n",
    "        )\n",
    "    return minimal_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "aab17388",
   "metadata": {},
   "outputs": [],
   "source": [
    "minimal_docs = filter_to_minimal_docs(extracted_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7871626e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_split(minimal_docs):\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=500,\n",
    "        chunk_overlap=20,\n",
    "    )\n",
    "    text_chunks = text_splitter.split_documents(minimal_docs)\n",
    "    return text_chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3a575c6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num of chunks: 1611\n"
     ]
    }
   ],
   "source": [
    "texts_chunk = text_split(minimal_docs)\n",
    "print(f\"num of chunks: {len(texts_chunk)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "87db50ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "\n",
    "def download_embeddings():\n",
    "    \"\"\" \n",
    "    Download and return the HuggingFace embeddings model.\n",
    "    \"\"\"\n",
    "    model_name = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
    "    embeddings = HuggingFaceEmbeddings(\n",
    "        model_name = model_name\n",
    "    )\n",
    "    return embeddings\n",
    "\n",
    "embedding = download_embeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "db9a9312",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HuggingFaceEmbeddings(client=SentenceTransformer(\n",
       "  (0): Transformer({'max_seq_length': 256, 'do_lower_case': False}) with Transformer model: BertModel \n",
       "  (1): Pooling({'word_embedding_dimension': 384, 'pooling_mode_cls_token': False, 'pooling_mode_mean_tokens': True, 'pooling_mode_max_tokens': False, 'pooling_mode_mean_sqrt_len_tokens': False, 'pooling_mode_weightedmean_tokens': False, 'pooling_mode_lasttoken': False, 'include_prompt': True})\n",
       "  (2): Normalize()\n",
       "), model_name='sentence-transformers/all-MiniLM-L6-v2', cache_folder=None, model_kwargs={}, encode_kwargs={}, multi_process=False, show_progress=False)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ffb78044",
   "metadata": {},
   "outputs": [],
   "source": [
    "vector = embedding.aembed_query(\"Hello world\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5ea62e4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9148e61b",
   "metadata": {},
   "outputs": [],
   "source": [
    "PINECONE_API_KEY = os.getenv(\"PINECONE_API_KEY\")\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "os.environ[\"PINECONE_API_KEY\"] = PINECONE_API_KEY\n",
    "os.environ[\"OPENAI_API_KEY\"] = OPENAI_API_KEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "cc1cb60a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pinecone import Pinecone\n",
    "pinecone_api_key = PINECONE_API_KEY\n",
    "\n",
    "pc = Pinecone(api_key=pinecone_api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0c1f4c9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8524bf18",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pinecone import ServerlessSpec\n",
    "\n",
    "index_name = \"medical-lab-chatbot\"\n",
    "\n",
    "if not pc.has_index(index_name):\n",
    "    pc.create_index(\n",
    "        name = index_name,\n",
    "        dimension=384,\n",
    "        metric=\"cosine\",\n",
    "        spec = ServerlessSpec(cloud=\"aws\", region=\"us-east-1\")\n",
    "    )\n",
    "\n",
    "index = pc.Index(index_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "dc75c6d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/medibot/lib/python3.10/site-packages/torch/nn/modules/module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "from langchain_pinecone import PineconeVectorStore\n",
    "\n",
    "docsearch = PineconeVectorStore.from_documents(\n",
    "    documents=texts_chunk,\n",
    "    embedding=embedding,\n",
    "    index_name=index_name\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9d992754",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_pinecone import PineconeVectorStore\n",
    "docsearch = PineconeVectorStore.from_existing_index(\n",
    "    index_name=index_name,\n",
    "    embedding=embedding\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "974cd3e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# option to add more data to existing data index\n",
    "\"\"\"\n",
    "dswith = Document(\n",
    "    page_content=\"placeholder for future documents\",\n",
    "    metadata={\"source\": \"lab\"}\n",
    ")\n",
    "\n",
    "docsearch.add_documents(documents=[dswith])\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "78716d8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = docsearch.as_retriever(search_type = \"similarity\", search_kwarts={\"k\":3})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3e024f1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/medibot/lib/python3.10/site-packages/torch/nn/modules/module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Document(id='1f238c1f-589d-42ea-a466-e15a2b046a06', metadata={'source': 'data/5812IFU.pdf'}, page_content='when there is no order (requisition) available for a sample, for example with a\\nsample ID read error. In the QC tab, you can program default QC profiles\\n(numbers 87 to 98) for each sample type and Group. The default QC profile is\\nthe automatic QC order (requisition) made after a reagent check.\\nd. In Profile Name, select a profile.\\ne. Select the test. The system displays the selected tests in blue.\\nf. Confirm that the information is correct, and then select Confirm (F1).'),\n",
       " Document(id='62c42e98-896c-436b-bc01-eb3334ae397c', metadata={'source': 'data/5812IFU.pdf'}, page_content='Figure 2.34 Rack Requisition: QC Screen\\n2 In Type, select the sample type.\\nThe system displays the tests automatically ordered (requisitioned) for QC in blue.\\nNOTE\\nTests are automatically ordered (requisitioned) for QC after the following:\\n— You perform a reagent check. This orders (requisitions) the Default QC profile.\\n— You select Auto CAL/QC Requisition (F3) or QC Same Requisition (F4) in the\\nCalibration screen. This orders (requisitions) the same QC tests as were ordered'),\n",
       " Document(id='2a764346-8f54-4478-a6ff-a7f0f8d6e693', metadata={'source': 'data/5812IFU.pdf'}, page_content='— If it is necessary to program a new QC sample:\\na. Select Edit (F1).\\nb. Select an available No. or Cup Position by Type.\\nc. Enter the Control Name, ID, Lot No., Expiration, and Multi Rack.\\nNOTE\\nIf Barcode Operation is not enabled, enter the Control Name. If Barcode\\nOperation is enabled, enter the Control Name and Control ID. The Lot No.,\\nExpiration, and Multi Rack are optional fields.\\nd. Confirm that the information is correct, and then select Confirm (F1).\\n9 Select QC Specific.'),\n",
       " Document(id='b9c4bd04-40b1-4f40-8639-892bbd53324b', metadata={'source': 'data/5812IFU.pdf'}, page_content='Create a QC Profile\\nQC profiles 87 to 98 are the default QC profiles that are automatically ordered\\n(requisitioned) in Home > Rack Requisition > QC. The QC profile numbers 87 to 98\\ncorrespond to a specific Group and sample type:\\n• Number 87: Serum: For Group 1\\n• Number 88: Serum: For Group 2\\n• Number 89: Serum: For Group 3\\n• Number 90: Urine: For Group 1\\n• Number 91: Urine: For Group 2\\n• Number 92: Urine: For Group 3\\n• Number 93: Other-1: For Group 1\\n• Number 94: Other-1: For Group 2')]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retrived_docs = retriever.invoke(\"How do I order QC?\")\n",
    "retrived_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f82bead5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "chatModel = ChatOpenAI(model=\"gpt-5-mini\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a0dd40fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import create_retrieval_chain\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain_core.prompts import ChatPromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7b41016b",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = (\n",
    "    \"You are an expert in medical laboratory analyzers for question-answering tasks. \"\n",
    "    \"Use the following pieces of retrieved context to answer \"\n",
    "    \"the question. If you don't know the answer, say that you \"\n",
    "    \"don't know. Use bullets or complete sentences depending on the question and keep the \"\n",
    "    \"answer concise.\"\n",
    "    \"\\n\\n\"\n",
    "    \"{context}\"\n",
    ")\n",
    "\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system_prompt),\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c4f626e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "question_answer_chain = create_stuff_documents_chain(chatModel, prompt)\n",
    "rag_chain = create_retrieval_chain(retriever, question_answer_chain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "2368d2c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/medibot/lib/python3.10/site-packages/torch/nn/modules/module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Brief step-by-step (based on the analyzer reagent-management functions and reagent constraints):\n",
      "\n",
      "- Open the Reagent Management / Reagent Setting screen (Reagent Management main tab).\n",
      "- Create a new reagent entry (or edit an existing one).\n",
      "- Set the Reagent Setting Method to \"Turn table method.\"\n",
      "- Select reagent Type: Normal concentration reagent or Highly concentrated reagent.\n",
      "- Set the Number of Reagent Steps (1–3).\n",
      "- Enter reagent volumes for each step in 1 µL increments. Observe these limits:\n",
      "  - Normal dispensing range: 10–170 µL per dispense.\n",
      "  - R1 ≤ 170 µL; R2 ≤ 170 µL.\n",
      "  - Total R1 + R2 ≤ 270 µL.\n",
      "  - For 3‑step reagents: R1‑1 + R1‑2 ≤ 170 µL.\n",
      "- Assign the physical bottle position on the turn table and enter ID/lot/expiry information.\n",
      "- Save the reagent definition.\n",
      "- Place the bottle in the assigned position and run Reagent Check (F5) — the system will detect the bottle, read the reagent ID and calculate remaining volume.\n",
      "- Note: the system dispenses with a micro‑syringe that has probe collision detection (no separate user setup usually required).\n",
      "\n",
      "If you need the exact menu names or screenshots for your software version, tell me the analyzer model and I can give step‑by‑step screen navigation.\n"
     ]
    }
   ],
   "source": [
    "response = rag_chain.invoke({\"input\": \"How do I program a custom reagent?\"})\n",
    "\n",
    "print(response[\"answer\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "medibot",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
